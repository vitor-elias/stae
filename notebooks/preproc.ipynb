{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tsmoothie import LowessSmoother, ExponentialSmoother\n",
    "from pyprojroot import here\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "ROOT_DIR = str(here())\n",
    "insar_dir = '/Users/vitorro/Repositories/dario/data/raw/insar/'\n",
    "data_dir = '/Users/vitorro/Repositories/dario/data/interim/'\n",
    "\n",
    "pio.templates.default = 'plotly'\n",
    "\n",
    "files = glob.glob(insar_dir + '/**/*.csv', recursive=True)\n",
    "for file in sorted(files):\n",
    "    print(file)\n",
    "\n",
    "\n",
    "def interpolate_displacement(df):\n",
    "    interpolated_df = df.set_index('timestamp').resample('6D').ffill()\n",
    "    interpolated_df['displacement'] = (\n",
    "                                       df[['timestamp','displacement']].set_index('timestamp')\n",
    "                                                                       .resample('6D')\n",
    "                                                                       .interpolate(method='linear')\n",
    "                                      )\n",
    "    return interpolated_df\n",
    "\n",
    "def smoothing(frac):\n",
    "    def smoothing_(x):\n",
    "        lowess_smoother = LowessSmoother(smooth_fraction=frac, iterations=1) #0.075 \n",
    "        lowess_smoother.smooth(x)\n",
    "        return lowess_smoother.smooth_data[0]\n",
    "    return smoothing_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading original file\n",
    "\n",
    "# df_orig = pd.read_csv(insar_dir+\"D1/L2B_066_0716_IW3_VV.csv\") # Gjerdrun D1\n",
    "# df_orig = pd.read_csv(insar_dir+\"/A1/L2B_117_0350_IW3_VV.csv\") # New Prorsgrunn A1\n",
    "# df_orig = pd.read_csv(insar_dir+\"/A1/L2B_117_0345_IW2_VV.csv\") # New Kristiansand A1\n",
    "# df_orig = pd.read_csv(insar_dir+\"D2/L2B_139_0696_IW3_VV.csv\") # New Trondheim D2\n",
    "# df_orig = pd.read_csv(insar_dir + \"A1/L2B_146_0377_IW2_VV.csv\") # New Trondheim A1\n",
    "df_orig = pd.read_csv(insar_dir + \"D1/L2B_037_0695_IW2_VV.csv\") # New Trondheim D1\n",
    "# df_orig = pd.read_csv(insar_dir+\"A1/146_0377_iw2_vv.csv\") # Trondheim A1\n",
    "# df_orig = pd.read_csv(insar_dir+\"D2/139_0696_iw3_vv.csv\") # TD2\n",
    "# df_orig = pd.read_csv(insar_dir + \"D1/037_0695_iw2_vv.csv\") # Trondheim\n",
    "# df_orig = pd.read_csv(insar_dir+\"D2/168_0743_iw2_vv.csv\") # Malmo D2\n",
    "# df_orig = pd.read_csv(insar_dir+\"066_0742_iw1_vv.csv\")  # Malmo D1<\n",
    "# # df_orig = pd.read_csv(insar_dir+\"066_0744_iw1_vv.csv\")\n",
    "\n",
    "fig = px.density_heatmap(x=df_orig.longitude, y=df_orig.latitude, nbinsx = 100, nbinsy=100, width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT AND FORMAT DATA\n",
    "df = df_orig.copy()\n",
    "\n",
    "lat_min, lat_max, lon_min, lon_max = (63.4182, 63.4220, 10.3858, 10.3946) # St. Olavs\n",
    "\n",
    "# lat_min, lat_max, lon_min, lon_max = (60.02, 60.25, 10.9, 11.4) # Gjerdrum\n",
    "\n",
    "# lat_min, lat_max, lon_min, lon_max = (59.10, 59.20, 9.55, 9.74) # 1 - Porsgrunn\n",
    "# lat_min, lat_max, lon_min, lon_max = (58.13, 58.20, 7.9, 8.1) # 1 - Kristiansand\n",
    "# lat_min, lat_max, lon_min, lon_max = (63.41, 63.46, 10.36,10.50) # 1 - Trondheim\n",
    "\n",
    "# OLD\n",
    "# lat_min, lat_max, lon_min, lon_max = (55.55, 55.58, 12.9,13.1) # 1 - df_smoothed_01\n",
    "# lat_min, lat_max, lon_min, lon_max = (55.58, 55.6, 12.9,13.1) # 2 - df_smoothed_02.parq\n",
    "# lat_min, lat_max, lon_min, lon_max = (55.37, 55.42, 12.7, 13.1) # 3 - df_smoothed_03.parq\n",
    "\n",
    "df = df[ (df.longitude>lon_min) & (df.longitude<=lon_max) &\n",
    "            (df.latitude>lat_min) & (df.latitude<=lat_max)  ]\n",
    "\n",
    "df = df[~((df.latitude>60.2356)&(df.longitude>11.1388))] # Cutting of RÃ¥holt from Gjerdrum\n",
    "\n",
    "fig = px.density_heatmap(x=df.longitude, y=df.latitude, nbinsx = 100, nbinsy=100, width=500, height=00)\n",
    "fig.show()\n",
    "\n",
    "# Selection relevant columns\n",
    "date_cols = sorted([col for col in df.columns if \"20\" in col]) #columns named after timestamps\n",
    "keep_cols = date_cols #list with variables to keep from dataframe\n",
    "id_cols = ['pid', 'latitude', 'longitude', 'easting', 'northing', 'mean_velocity']\n",
    "keep_cols.extend(id_cols)\n",
    "df = df[keep_cols]  #replacing old df for memory efficiency\n",
    "# df_originals.append(df)\n",
    "\n",
    "# Formatting from wide to tall dataframe\n",
    "# Uses a single column for timestamp and a column for displacement\n",
    "# Number of rows = number of pixels * number of timestamps\n",
    "df = df.melt(id_vars=id_cols, value_vars=date_cols,\n",
    "                var_name='timestamp', value_name='displacement').sort_values('pid')\n",
    "df.timestamp = pd.to_datetime(df.timestamp)\n",
    "\n",
    "# RETRO: based on gap before 2016.06\n",
    "df = df[df.timestamp>='2016-06-01'].copy()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.sort_values(['pid','timestamp'], inplace=True)\n",
    "\n",
    "# CLUSTERING PIXELS (to work with smaller groups at once later)\n",
    "\n",
    "average_size = 1000\n",
    "nodes_full = df.drop_duplicates(['pid'])[['pid', 'easting','northing']]\n",
    "nodes_full['cluster'] = KMeans(n_clusters=nodes_full.shape[0]//average_size).fit_predict(nodes_full[['northing','easting']])\n",
    "df = df.merge(nodes_full[['pid','cluster']], how='left', on='pid')\n",
    "\n",
    "print(f'{df.pid.nunique()} nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPOLATE MISSING TIMESTAMPS\n",
    "df = (df.groupby('pid', as_index=False)\n",
    "                .apply(interpolate_displacement)\n",
    "                .reset_index().drop('level_0', axis=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY SMOOTHNESS\n",
    "df['smoothed'] = df.groupby('pid',as_index=False).displacement.transform(smoothing(50/df.timestamp.nunique()))\n",
    "# df['smooth60'] = df.groupby('pid',as_index=False).displacement.transform(smoothing(60/df.timestamp.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "\n",
    "filename = 'df_StOlavs_D1L2B.parq'\n",
    "df.to_parquet(data_dir + f'{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.timestamp.dt.year.astype(str) + df.timestamp.dt.month.astype(str)\n",
    "# df = df.drop_duplicates(['pid','month'], keep='last').reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['motion'] = df.groupby('pid').smoothed.transform(lambda x: np.r_[0, np.diff(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df[df.pid==df.pid.unique()[0]], x='timestamp',\n",
    "        y=['displacement', '2 months', '10 months', '12 months'],\n",
    "        color_discrete_sequence=['skyblue', 'gray', 'red', 'limegreen'],\n",
    "        width=1000, height=600)\n",
    "fig.update_layout(font_family=\"Times New Roman\", font_size=14)\n",
    "fig.update_layout(xaxis={'showgrid':False})\n",
    "fig.write_image(ROOT_DIR+\"/models/outputs/figs/report/smoothness.png\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dario-juiScTYW-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "95ec3b9eedf9bbca5af024a8d2af376499af510a5403dc8040ac2fcf9913d231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
