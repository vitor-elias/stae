{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import contextily as cx\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import torch\n",
    "import joblib\n",
    "import calflops\n",
    "import time \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, auc, f1_score, matthews_corrcoef\n",
    "from calflops.flops_counter import calculate_flops\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn.cluster import KMeans\n",
    "from tsmoothie import LowessSmoother, ExponentialSmoother\n",
    "from pyprojroot import here\n",
    "from scipy.spatial import ConvexHull\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import source.nn.models as models\n",
    "import source.utils.utils as utils\n",
    "import source.utils.fault_detection as fd\n",
    "\n",
    "from source.utils.utils import roc_params, compute_auc, get_auc, best_mcc, best_f1score, otsuThresholding\n",
    "from source.utils.utils import synthetic_timeseries\n",
    "from source.utils.utils import plotly_signal\n",
    "\n",
    "from importlib import reload\n",
    "models = reload(models)\n",
    "utils = reload(utils)\n",
    "fd = reload(fd)\n",
    "\n",
    "from pyprojroot import here\n",
    "root_dir = str(here())\n",
    "\n",
    "insar_dir = os.path.expanduser('~/data/raw/')\n",
    "data_path = root_dir + '/data/interim/'\n",
    "dataset_path = root_dir + \"/data/datasets/\"\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'DejaVu Serif'})\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Test_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Geological_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "test_metrics = torch.load(root_dir + f'/outputs/Testing/Test_metrics_{dataset_name}.pkl')\n",
    "\n",
    "# Create a nicely formatted table showing test metrics for all models\n",
    "metrics_df = pd.DataFrame()\n",
    "for model in test_metrics.keys():\n",
    "    metrics_df.loc[model, 'AUC'] = f\"{test_metrics[model]['mean_auc']:.3f} ± {test_metrics[model]['std_auc']:.3f}\"\n",
    "    metrics_df.loc[model, 'Oslo'] = f\"{test_metrics[model]['oslo_auc']:.3f}\"\n",
    "    metrics_df.loc[model, 'Malmo'] = f\"{test_metrics[model]['malmo_auc']:.3f}\"\n",
    "\n",
    "    metrics_df.loc[model, 'F1'] = f\"{test_metrics[model]['mean_f1']:.3f} ± {test_metrics[model]['std_f1']:.3f}\"\n",
    "    metrics_df.loc[model, 'MCC'] = f\"{test_metrics[model]['mean_mcc']:.3f} ± {test_metrics[model]['std_mcc']:.3f}\"\n",
    "\n",
    "print(metrics_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "test_metrics = torch.load(root_dir + f'/outputs/Testing/Test_metrics_{dataset_name}.pkl')\n",
    "\n",
    "# Create a nicely formatted table showing test metrics for all models\n",
    "metrics_df = pd.DataFrame()\n",
    "for model in test_metrics.keys():\n",
    "    metrics_df.loc[model, 'AUC'] = f\"{test_metrics[model]['mean_auc']:.3f} ± {test_metrics[model]['std_auc']:.3f}\"\n",
    "    metrics_df.loc[model, 'Oslo'] = f\"{test_metrics[model]['oslo_auc']:.3f}\"\n",
    "    metrics_df.loc[model, 'Malmo'] = f\"{test_metrics[model]['malmo_auc']:.3f}\"\n",
    "\n",
    "    metrics_df.loc[model, 'F1'] = f\"{test_metrics[model]['mean_f1']:.3f} ± {test_metrics[model]['std_f1']:.3f}\"\n",
    "    metrics_df.loc[model, 'MCC'] = f\"{test_metrics[model]['mean_mcc']:.3f} ± {test_metrics[model]['std_mcc']:.3f}\"\n",
    "\n",
    "print(metrics_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_accuracy(metric, labels, interp=True):\n",
    "    label = labels.any(axis=1)\n",
    "    \n",
    "    thr_list = list(np.linspace(metric.min(), metric.max(),101))\n",
    "\n",
    "    f1score = []\n",
    "    for threshold in thr_list[0:-1]:\n",
    "        y = (metric>threshold)\n",
    "        f1score.append(f1_score(label, y))\n",
    "\n",
    "    label_1 = (labels==1).any(axis=1)\n",
    "    label_2 = (labels==2).any(axis=1)\n",
    "\n",
    "    thr_max = thr_list[np.argmax(f1score)]\n",
    "    detections = (metric>thr_max)\n",
    "    \n",
    "    # Calculate accuracy for label_1\n",
    "    true_positives = np.sum(detections & label_1)\n",
    "    total_label_1 = np.sum(label_1)\n",
    "    accuracy_label_1 = true_positives / total_label_1 if total_label_1 > 0 else 0\n",
    "\n",
    "    # Calculate accuracy for label_2\n",
    "    true_positives = np.sum(detections & label_2)\n",
    "    total_label_2 = np.sum(label_2)\n",
    "    accuracy_label_2 = true_positives / total_label_2 if total_label_2 > 0 else 0   \n",
    "    \n",
    "    return accuracy_label_1, accuracy_label_2\n",
    "\n",
    "for dataset_name in ['Geological_anomaly', 'EGMS_anomaly']:\n",
    "\n",
    "    datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "    model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "    model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    accuracy_dict = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"Computing metrics for {model_name}\")\n",
    "        acc1_list = []\n",
    "        acc2_list = []\n",
    "        \n",
    "        for idx, dataset in enumerate(datasets):\n",
    "            print(f\"\\rProcessing dataset {idx+1}/{len(datasets)} for model {model_name}\", end='', flush=True)\n",
    "\n",
    "            acc1_seed = []\n",
    "            acc2_seed = []\n",
    "            for seed in range(25):\n",
    "                # Compute metrics for each dataset based on each label being true if any anomaly is present\n",
    "                scores = model_dict[model_name]['scores'][idx][seed]\n",
    "                \n",
    "                acc1, acc2 = label_accuracy(scores, dataset['label'])\n",
    "                acc1_seed.append(acc1)\n",
    "                acc2_seed.append(acc2)\n",
    "\n",
    "            acc1_list.append(acc1_seed)\n",
    "            acc2_list.append(acc2_seed)\n",
    "        \n",
    "        # Store metrics and compute statistics\n",
    "        accuracy_dict[model_name] = {\n",
    "            'mean_acc1': np.mean(np.mean(acc1_list,axis=0)).round(3),\n",
    "            'std_acc1': np.mean(np.mean(acc1_list,axis=0)).round(3),\n",
    "            'mean_acc2': np.mean(np.mean(acc2_list,axis=0)).round(3),\n",
    "            'std_acc2': np.std(np.mean(acc2_list,axis=0)).round(3),\n",
    "        }\n",
    "        print(\"\\n\")\n",
    "\n",
    "    torch.save(accuracy_dict, root_dir + f'/outputs/Testing/Test_accuracy_{dataset_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Geological_anomaly'\n",
    "accuracy_dict = torch.load(root_dir + f'/outputs/Testing/Test_accuracy_{dataset_name}.pkl')\n",
    "accuracy_df = pd.DataFrame()\n",
    "for model in accuracy_dict.keys():\n",
    "    accuracy_df.loc[model, 'Geological'] = f\"{accuracy_dict[model]['mean_acc1']:.3f} ± {accuracy_dict[model]['std_acc1']:.3f}\"\n",
    "    accuracy_df.loc[model, 'Phase'] = f\"{accuracy_dict[model]['mean_acc2']:.3f} ± {accuracy_dict[model]['std_acc2']:.3f}\"\n",
    "\n",
    "print(accuracy_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "accuracy_dict = torch.load(root_dir + f'/outputs/Testing/Test_accuracy_{dataset_name}.pkl')\n",
    "accuracy_df = pd.DataFrame()\n",
    "for model in accuracy_dict.keys():\n",
    "    accuracy_df.loc[model, 'Geological'] = f\"{accuracy_dict[model]['mean_acc1']:.3f} ± {accuracy_dict[model]['std_acc1']:.3f}\"\n",
    "    accuracy_df.loc[model, 'Phase'] = f\"{accuracy_dict[model]['mean_acc2']:.3f} ± {accuracy_dict[model]['std_acc2']:.3f}\"\n",
    "\n",
    "print(accuracy_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "# Select models to visualize\n",
    "models_to_plot = ['AE', 'GCN2MLP', 'RAE_LSTM']\n",
    "i = 20  # First dataset\n",
    "seed = 0\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(2, 2, width_ratios=[1, 1])\n",
    "\n",
    "# Plot the true labels first\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "labels = datasets[i]['label'].max(axis=1)\n",
    "colors = [(0.5, 0.5, 0.8), (0.05, 0.25, 0.25), (0.55, 0.55, 0.05)] \n",
    "scatter_groups = []\n",
    "labels_unique = np.unique(labels)\n",
    "\n",
    "for label_val, color in zip(labels_unique, colors):\n",
    "    mask = (labels == label_val)\n",
    "    scatter = ax1.scatter(\n",
    "        datasets[i]['pos'][mask,0],\n",
    "        datasets[i]['pos'][mask,1],\n",
    "        color=color,\n",
    "        s=50,\n",
    "    )\n",
    "    scatter_groups.append(scatter)\n",
    "\n",
    "ax1.legend(['Normal', 'Geological', 'Phase'], loc='upper left')\n",
    "ax1.set_title('Labels')\n",
    "ax1.axis('off')\n",
    "cx.add_basemap(ax1, crs='EPSG:3035', source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# Create scatter plots for each model\n",
    "axes = []\n",
    "for idx in range(len(models_to_plot)):\n",
    "    row = (idx + 1) // 2\n",
    "    col = (idx + 1) % 2\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    axes.append(ax)\n",
    "\n",
    "vmin, vmax = 0, 1  # Set consistent color scale\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "for idx, (ax, model_name) in enumerate(zip(axes, models_to_plot)):\n",
    "    scores = model_dict[model_name]['scores'][i][seed]\n",
    "    scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        datasets[i]['pos'][:,0],\n",
    "        datasets[i]['pos'][:,1],\n",
    "        c=scores,\n",
    "        cmap='PuRd',\n",
    "        s=100,\n",
    "        norm=norm\n",
    "    )\n",
    "    ax.set_title(model_name.replace('_', ''))\n",
    "    ax.axis('off')\n",
    "    cx.add_basemap(ax, crs='EPSG:3035', source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# Add colorbar\n",
    "cbar_ax = fig.add_axes([1., 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "plt.colorbar(scatter, cax=cbar_ax, label='Normalized Anomaly Score')\n",
    "\n",
    "plt.tight_layout(pad=1.0)\n",
    "plt.savefig(root_dir + f'/outputs/figs/{dataset_name}_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "# Select models to visualize\n",
    "models_to_plot = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "i = 20  # Dataset index\n",
    "seed = 0\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "vmin, vmax = 0, 1  # Set consistent color scale\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "for idx, (ax, model_name) in enumerate(zip(axes, models_to_plot)):\n",
    "    scores = model_dict[model_name]['scores'][i][seed]\n",
    "    scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        datasets[i]['pos'][:,0],\n",
    "        datasets[i]['pos'][:,1],\n",
    "        c=scores,\n",
    "        cmap='PuRd',\n",
    "        s=100,\n",
    "        norm=norm\n",
    "    )\n",
    "    ax.set_title(model_name.replace('_', ''))\n",
    "    ax.axis('off')\n",
    "    cx.add_basemap(ax, crs='EPSG:3035', source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# Add colorbar\n",
    "cbar_ax = fig.add_axes([1.0, 0.10, 0.02, 0.75])  # [left, bottom, width, height]\n",
    "cbar = plt.colorbar(scatter, cax=cbar_ax)\n",
    "cbar.set_label('Normalized Anomaly Score', fontsize=32)\n",
    "\n",
    "plt.tight_layout(pad=1.0)\n",
    "plt.savefig(root_dir + f'/outputs/figs/{dataset_name}_scores_all.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "# Select models to visualize\n",
    "models_to_plot = ['GUNet', 'AE', 'RAE_GRU']\n",
    "i = 0  # First dataset\n",
    "seed = 0\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['True Labels'] + models_to_plot,\n",
    "    vertical_spacing=0.08,\n",
    "    horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "# Plot the true labels first\n",
    "labels = datasets[i]['label'].max(axis=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=datasets[i]['pos'][:,0],\n",
    "        y=datasets[i]['pos'][:,1], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=labels,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(len=0.4, y=0.8)\n",
    "        ),\n",
    "        hovertemplate='<br>'.join([\n",
    "            'x: %{x}',\n",
    "            'y: %{y}',\n",
    "            'Label: %{marker.color:.2f}'\n",
    "        ]),\n",
    "        name='True Labels'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Create scatter plots for each model\n",
    "for idx, model_name in enumerate(models_to_plot):\n",
    "    scores = model_dict[model_name]['scores'][i][seed]\n",
    "    \n",
    "    # Normalize scores to [0, 1]\n",
    "    scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "    \n",
    "    row = (idx + 1) // 2 + 1\n",
    "    col = (idx + 1) % 2 + 1\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=datasets[i]['pos'][:,0],\n",
    "            y=datasets[i]['pos'][:,1], \n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=scores,\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(len=0.4, y=0.8 if col==1 else 0.3)\n",
    "            ),\n",
    "            hovertemplate='<br>'.join([\n",
    "                'x: %{x}',\n",
    "                'y: %{y}',\n",
    "                'Score: %{marker.color:.3f}'\n",
    "            ]),\n",
    "            name=model_name\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=20, r=20, t=40, b=20),\n",
    "    font=dict(size=14),\n",
    ")\n",
    "\n",
    "# Hide all axes\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_yaxes(visible=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = torch.load(root_dir + f'/outputs/Testing/Scores_real_data.pkl')\n",
    "df_Oslo = pd.read_parquet('/home/vitorro/Repositories/stae/data/interim/df_Oslo.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = model_results['GCN2MLP']\n",
    "df_results = []\n",
    "\n",
    "for data in datasets:\n",
    "    df = pd.DataFrame({'easting': data['pos'][:,0],\n",
    "                'northing': data['pos'][:,1],\n",
    "                'latitude': data['coords'][:,0],\n",
    "                'longitude': data['coords'][:,1],\n",
    "                'pid': data['pid'],\n",
    "                'scores': data['scores']/data['scores'].max(),\n",
    "                })\n",
    "    df_results.append(df)\n",
    "df_results = pd.concat(df_results, ignore_index=True)\n",
    "df_results = df_results.sort_values('scores', ascending=False).drop_duplicates(subset=['easting', 'northing'], keep='first')\n",
    "\n",
    "df_gcn2mlp = df_results.query('scores > 0.75').copy()\n",
    "\n",
    "utils.visualize_map(df_gcn2mlp, color='scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = model_results['GUNet']\n",
    "df_results = []\n",
    "\n",
    "for data in datasets:\n",
    "    df = pd.DataFrame({'easting': data['pos'][:,0],\n",
    "                'northing': data['pos'][:,1],\n",
    "                'latitude': data['coords'][:,0],\n",
    "                'longitude': data['coords'][:,1],\n",
    "                'pid': data['pid'],\n",
    "                'scores': data['scores']/data['scores'].max(),\n",
    "                })\n",
    "    df_results.append(df)\n",
    "df_results = pd.concat(df_results, ignore_index=True)\n",
    "df_results = df_results.sort_values('scores', ascending=False).drop_duplicates(subset=['easting', 'northing'], keep='first')\n",
    "\n",
    "df_gunet = df_results.query('scores > 0.75').copy()\n",
    "\n",
    "utils.visualize_map(df_gunet, color='scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gcn2mlp['type'] = 0\n",
    "df_gunet['type'] = 1\n",
    "df_combined = pd.concat([df_gcn2mlp, df_gunet], ignore_index=True)\n",
    "\n",
    "df_type = df_combined.groupby('pid', as_index=False).mean()\n",
    "\n",
    "conditions = [\n",
    "    df_type['type'] == 0,\n",
    "    df_type['type'] == 1\n",
    "]\n",
    "choices = ['GCN2MLP', 'GUNet']\n",
    "\n",
    "df_type['type'] = np.select(conditions, choices, default='Both')\n",
    "df_type['norm_scores'] = (df_type['scores'] - df_type['scores'].min()) / (df_type['scores'] - df_type['scores'].min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, subs = fd.NNGraph(df_type, radius=20, subgraphs=True)\n",
    "df_type['subgraph'] = subs\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define colors for each type\n",
    "color_dict = {\n",
    "    'GCN2MLP': 'red',\n",
    "    'GUNet': 'blue',\n",
    "    'Both': 'limegreen'\n",
    "}\n",
    "\n",
    "# Create scatter plot for each unique type\n",
    "for type_val in df_type['type'].unique():\n",
    "    mask = df_type['type'] == type_val\n",
    "    plt.scatter(\n",
    "        df_type[mask]['easting'], \n",
    "        df_type[mask]['northing'],\n",
    "        label=type_val,\n",
    "        color=color_dict[type_val],\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "annotated = []\n",
    "# annotate each position in G.coords with the value in subs\n",
    "for i, pos in enumerate(G.coords):\n",
    "    x_pos = pos[0]\n",
    "    y_pos = pos[1]\n",
    "    x_offset = 20\n",
    "    y_offset = 20\n",
    "\n",
    "    if (subs[i] not in annotated) or (subs[i]==0):\n",
    "        plt.annotate(f\"{subs[i]:.0f}\", (x_pos, y_pos), xytext=(x_pos + x_offset, y_pos + y_offset), fontsize=12, color='black', ha='center', va='center')\n",
    "\n",
    "    annotated.append(subs[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "cx.add_basemap(plt.gca(), crs='EPSG:3035', source=cx.providers.CartoDB.Positron)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = utils.visualize_map(df_type, color='type', size='norm_scores', size_max=6, zoom=14, discrete_colormap=['blue','red','limegreen'], return_fig=True)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0.25,          # x position (0 = left, 1 = right)\n",
    "        y=0.25,          # y position (0 = bottom, 1 = top)\n",
    "        xanchor='right', # anchor the x position to the 'right' of the box\n",
    "        yanchor='top',   # anchor the y position to the 'top' of the box\n",
    "        bgcolor='rgba(255,255,255,0.8)',  # optional: add background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "        font=dict(family=\"Times New Roman, Times, serif\", size=24),\n",
    "        title='',\n",
    "    ),\n",
    "    margin=dict(l=20, r=20, t=20, b=20),  # Reduced margins\n",
    "    width=1200,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# saving figure as pdf\n",
    "# fig.write_image(root_dir + f'/outputs/figs/Types.pdf', width=800, height=600, scale=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter and prepare data\n",
    "# subgraph = [57, 60]\n",
    "subgraph = [63]\n",
    "df_sub = df_type[df_type['subgraph'].isin(subgraph)].copy()\n",
    "pid_list = df_sub.pid.values\n",
    "type_map = dict(zip(df_sub.pid, df_sub.type))\n",
    "\n",
    "df_filtered = df_Oslo[df_Oslo['pid'].isin(pid_list)].copy()\n",
    "df_filtered['type'] = df_filtered['pid'].map(type_map)\n",
    "\n",
    "color_dict = {\n",
    "    'GCN2MLP': 'red',\n",
    "    'GUNet': 'blue',\n",
    "    'Both': 'limegreen'\n",
    "}\n",
    "pid_color_map = {pid: color_dict[type_map[pid]] for pid in pid_list}\n",
    "\n",
    "# 2. Create main scatter plot (color by pid to get trendlines per pid)\n",
    "fig = px.scatter(\n",
    "    df_filtered,\n",
    "    x='timestamp',\n",
    "    y='displacement',\n",
    "    color='pid',\n",
    "    color_discrete_map=pid_color_map,\n",
    "    trendline='lowess',\n",
    "    template='simple_white',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    labels={'timestamp': 'Timestamp', 'displacement': 'Displacement (mm)'},\n",
    ")\n",
    "\n",
    "# Update layout with box around plot and reduced margins\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Times New Roman, Times, serif\", size=18),\n",
    "    showlegend=False,\n",
    "    margin=dict(l=50, r=20, t=20, b=50),  # Reduced margins\n",
    "    xaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    "    yaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/Types_both_63.pdf', width=800, height=600, scale=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter and prepare data\n",
    "subgraph = [57, 60]\n",
    "# subgraph = [31]\n",
    "df_sub = df_type[df_type['subgraph'].isin(subgraph)].copy()\n",
    "pid_list = df_sub.pid.values\n",
    "type_map = dict(zip(df_sub.pid, df_sub.type))\n",
    "\n",
    "df_filtered = df_Oslo[df_Oslo['pid'].isin(pid_list)].copy()\n",
    "df_filtered['type'] = df_filtered['pid'].map(type_map)\n",
    "\n",
    "color_dict = {\n",
    "    'GCN2MLP': 'red',\n",
    "    'GUNet': 'blue',\n",
    "    'Both': 'limegreen'\n",
    "}\n",
    "pid_color_map = {pid: color_dict[type_map[pid]] for pid in pid_list}\n",
    "\n",
    "# 2. Create main scatter plot (color by pid to get trendlines per pid)\n",
    "fig = px.scatter(\n",
    "    df_filtered,\n",
    "    x='timestamp',\n",
    "    y='displacement',\n",
    "    color='pid',\n",
    "    color_discrete_map=pid_color_map,\n",
    "    trendline='lowess',\n",
    "    template='simple_white',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    labels={'timestamp': 'Timestamp', 'displacement': 'Displacement (mm)'},\n",
    ")\n",
    "\n",
    "# Update layout with box around plot and reduced margins\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Times New Roman, Times, serif\", size=18),\n",
    "    showlegend=False,\n",
    "    margin=dict(l=50, r=20, t=20, b=50),  # Reduced margins\n",
    "    xaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    "    yaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/Types_GCN2MLP_57.pdf', width=800, height=600, scale=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter and prepare data\n",
    "subgraph = [53]\n",
    "df_sub = df_type[df_type['subgraph'].isin(subgraph)].copy()\n",
    "pid_list = df_sub.pid.values\n",
    "type_map = dict(zip(df_sub.pid, df_sub.type))\n",
    "\n",
    "df_filtered = df_Oslo[df_Oslo['pid'].isin(pid_list)].copy()\n",
    "df_filtered['type'] = df_filtered['pid'].map(type_map)\n",
    "\n",
    "color_dict = {\n",
    "    'GCN2MLP': 'red',\n",
    "    'GUNet': 'blue',\n",
    "    'Both': 'limegreen'\n",
    "}\n",
    "pid_color_map = {pid: color_dict[type_map[pid]] for pid in pid_list}\n",
    "\n",
    "# 2. Create main scatter plot (color by pid to get trendlines per pid)\n",
    "fig = px.scatter(\n",
    "    df_filtered,\n",
    "    x='timestamp',\n",
    "    y='displacement',\n",
    "    color='pid',\n",
    "    color_discrete_map=pid_color_map,\n",
    "    trendline='lowess',\n",
    "    template='simple_white',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    labels={'timestamp': 'Timestamp', 'displacement': 'Displacement (mm)'},\n",
    ")\n",
    "\n",
    "# Update layout with box around plot and reduced margins\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Times New Roman, Times, serif\", size=18),\n",
    "    showlegend=False,\n",
    "    margin=dict(l=50, r=20, t=20, b=50),  # Reduced margins\n",
    "    xaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    "    yaxis=dict(showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/Types_GUNet_53.pdf', width=800, height=600, scale=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_results.query('scores >= 0.89').copy()\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "scatter = plt.scatter(df_plot['easting'], df_plot['northing'], c=df_plot['scores'], \n",
    "                     cmap='PuRd', s=10*df_plot['scores'], alpha=0.6)\n",
    "tick_values = np.arange(0.7, 1.1, 0.1)  \n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Anomaly Score', ticks=tick_values)\n",
    "cbar.ax.set_yticklabels([f'{t:.1f}' for t in tick_values])  # optional\n",
    "\n",
    "# plt.colorbar(scatter, label='Anomaly Score')\n",
    "plt.axis('off')\n",
    "\n",
    "cx.add_basemap(ax, crs='EPSG:3035', source=cx.providers.CartoDB.Positron)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = 63\n",
    "pid_list = df_type.query('subgraph == @subgraph').pid.values\n",
    "type_list = df_type.query('subgraph == @subgraph').type.values\n",
    "\n",
    "color_dict = {\n",
    "    'GCN2MLP': 'red',\n",
    "    'GUNet': 'blue',\n",
    "    'Both': 'limegreen'\n",
    "}\n",
    "\n",
    "fig = px.scatter(df_Oslo[df_Oslo['pid'].isin(pid_list)], \n",
    "                 x='timestamp', \n",
    "                 y='displacement', \n",
    "                 color='pid', \n",
    "                 trendline='lowess',\n",
    "                 template='simple_white',\n",
    "                 width=1000, height=600,\n",
    "                 labels={'timestamp': 'Timestamp', 'displacement': 'Displacement (mm)'},\n",
    "                 )\n",
    "\n",
    "# Update font settings\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\",\n",
    "        size=18\n",
    "    ),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    print(f\"{model_name:<10}: - Geo: {metrics_dict[model_name]['mean_acc1']:<5}, Phase: {metrics_dict[model_name]['mean_acc2']:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "dataset = datasets[0]\n",
    "labels = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels==1).any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_dict['AE']['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(datasets[0]['label'].max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0]['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig = copy.deepcopy(model_dict['AE']['model'])\n",
    "\n",
    "# Modify input layer size\n",
    "model_orig.encoder[0].in_features = 300  # new input size\n",
    "model_orig.encoder[0].weight = torch.nn.Parameter(torch.randn(25, 300))  # new weight matrix\n",
    "model_orig.encoder[0].bias = torch.nn.Parameter(torch.randn(25))  # new bias vector\n",
    "\n",
    "# Modify output layer size\n",
    "model_orig.decoder[-1].out_features = 300  # new output size\n",
    "model_orig.decoder[-1].weight = torch.nn.Parameter(torch.randn(300, 25))  # new weight matrix\n",
    "model_orig.decoder[-1].bias = torch.nn.Parameter(torch.randn(300))  # new bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RAE_GRU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.split('_')[-1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['GUNet']['trial_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[150] + [model_dict['AE']['trial_params'][f'layer_dim_{i}'] for i in range(model_dict['AE']['trial_params']['n_layers'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "new_model_params = {key: getattr(model, key) for key in relevant_params}\n",
    "new_model_params['n_features'] = X.shape[0]\n",
    "model = models.RAE(**new_model_params)\n",
    "model.to(new_model_params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['AE']['model'].decoder[-1].out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_{dataset_name}.pkl')\n",
    "model_dict['AE'].keys()\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "# Base x locations\n",
    "x = np.arange(len(model_names))\n",
    "x_positions = 2*(x)\n",
    "\n",
    "# Extract num_parameters and total_params from model_dict\n",
    "num_parameters = [model_dict[model]['num_parameters'] for model in model_names]\n",
    "total_params = [model_dict[model]['num_parameters'] * model_dict[model]['trial_params']['n_epochs'] for model in model_names]\n",
    "\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for num_parameters\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions - bar_width / 2,\n",
    "    y=num_parameters,\n",
    "    width=bar_width,\n",
    "    name='Count of Trainable Parameters',\n",
    "    text=num_parameters,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Add bars for total_params\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions + bar_width / 2,\n",
    "    y=total_params,\n",
    "    width=bar_width,\n",
    "    name='Count of Parameter Updates',\n",
    "    text=total_params,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[m.replace('_','') for m in model_names],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickformat=\"~s\",\n",
    "        tickvals=[i*1000 for i in range(0, 1001, 100)],  # Example: 0k, 100k, 200k, ..., 1000k\n",
    "    ),\n",
    "    barmode='group',\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        x=0.02,  # Horizontal position of the legend\n",
    "        y=0.95,  # Vertical position of the legend\n",
    "        bgcolor='rgba(255,255,255,0.5)',  # Semi-transparent background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\",\n",
    "        size=18\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/complexity_parameters_EGMS.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Geological_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "# Base x locations\n",
    "x = np.arange(len(model_names))\n",
    "x_positions = 2*(x)\n",
    "\n",
    "# Extract num_parameters and total_params from model_dict\n",
    "num_parameters = [model_dict[model]['num_parameters'] for model in model_names]\n",
    "total_params = [model_dict[model]['num_parameters'] * model_dict[model]['trial_params']['n_epochs'] for model in model_names]\n",
    "\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for num_parameters\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions - bar_width / 2,\n",
    "    y=num_parameters,\n",
    "    width=bar_width,\n",
    "    name='Count of Trainable Parameters',\n",
    "    text=num_parameters,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Add bars for total_params\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions + bar_width / 2,\n",
    "    y=total_params,\n",
    "    width=bar_width,\n",
    "    name='Count of Parameter Updates',\n",
    "    text=total_params,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[m.replace('_','') for m in model_names],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickformat=\"~s\",\n",
    "        tickvals=[i*1000 for i in range(0, 1001, 100)],  # Example: 0k, 100k, 200k, ..., 1000k\n",
    "    ),\n",
    "    barmode='group',\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        x=0.02,  # Horizontal position of the legend\n",
    "        y=0.95,  # Vertical position of the legend\n",
    "        bgcolor='rgba(255,255,255,0.5)',  # Semi-transparent background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\",\n",
    "        size=18\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/complexity_parameters_Geological.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN Epoch_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_times_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'time_epoch'\n",
    "\n",
    "mean_times = {model: np.mean(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "std_times = {model: np.std(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "\n",
    "for model in model_names:\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  Epoch time: {mean_times[model]:.3f} +- {std_times[model]:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'time_total'\n",
    "\n",
    "mean_times = {model: np.mean(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "std_times = {model: np.std(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "\n",
    "for model in model_names:\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  Total time: {mean_times[model]:.3f} +- {std_times[model]:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_dict['AE']['model'].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model_dict['AE']['time_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_info in model_dict.items():\n",
    "    print(f\"{model_name}: {model_info['trial_params']['n_epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "dataset_path = root_dir + \"/data/datasets/\"\n",
    "datafile = 'EGMS_anomaly/Training/dataset.pt'\n",
    "datasets = torch.load(dataset_path + datafile)\n",
    "\n",
    "dataset = datasets[0]\n",
    "input_dim = datasets[0]['data'].shape[1]\n",
    "\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "\n",
    "X = torch.tensor(data).float().to( device )\n",
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_features': 2,\n",
    "                'latent_dim': 4,\n",
    "                'rnn_type': 'GRU',\n",
    "                'rnn_act': 'relu',\n",
    "                'device': device}\n",
    "batch_size = 512\n",
    "\n",
    "model_class = getattr(models, 'RAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if isinstance(model, models.RAE) and (model.n_features != 1):\n",
    "    relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "    new_model_params = {key: getattr(model, key) for key in relevant_params}\n",
    "    new_model_params['n_features'] = X.shape[0]\n",
    "    model = models.RAE(**new_model_params)\n",
    "    model.to(new_model_params['device'])\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'layer_dims':[input_dim, 4, 4]}\n",
    "\n",
    "model_class = getattr(models, 'GConvAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'layer_dims':[input_dim, 4, 4]}\n",
    "\n",
    "model_class = getattr(models, 'GCNAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'in_channels': input_dim,\n",
    "                'out_channels': input_dim,\n",
    "                'hidden_channels': 300,\n",
    "                'depth': 1,\n",
    "                'pool_ratios': 0.7}\n",
    "\n",
    "model_class = getattr(models, 'GUNet')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_mse(output,X):\n",
    "    point_mse = torch.nn.MSELoss(reduction='none')\n",
    "    return torch.mean(point_mse(output,X), axis=1)\n",
    "\n",
    "\n",
    "device = 'cuda:2'\n",
    "def train_model(model, X, label, lr, G=None):\n",
    "\n",
    "    rng_seed = 0\n",
    "    torch.manual_seed(rng_seed)\n",
    "    torch.cuda.manual_seed(rng_seed)\n",
    "    np.random.seed(rng_seed)\n",
    "\n",
    "    loss_epoch = []\n",
    "    auc_epoch = []\n",
    "    scores_epoch = []\n",
    "\n",
    "    if G is not None:\n",
    "        A = torch.tensor(G.W.toarray()).float()\n",
    "        A = A.to(device)    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    def pixel_mse(output,X):\n",
    "        point_mse = torch.nn.MSELoss(reduction='none')\n",
    "        return torch.mean(point_mse(output,X), axis=1)\n",
    "\n",
    "    model.train()\n",
    "    model.reset_parameters()\n",
    "\n",
    "    # for epoch in range(1, 1+np.max(epochs_list)):\n",
    "    for epoch in range(1,1000):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        if epoch in np.ceil(np.geomspace(1,1000,10)):\n",
    "\n",
    "\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            scores = pixel_mse(output, X).detach().cpu().numpy()\n",
    "            # scores_epoch.append(scores)\n",
    "\n",
    "            auc = get_auc(scores, label, resolution=101).round(3)\n",
    "            auc_epoch.append(auc)\n",
    "\n",
    "\n",
    "        # if epoch in epochs_list:\n",
    "        #     S_partials.append(S)...\n",
    "\n",
    "    return auc_epoch, loss_epoch\n",
    "\n",
    "def evaluate_model(model, datasets, lr):\n",
    "\n",
    "    auc_epoch_list = []\n",
    "    loss_epoch_list = []\n",
    "\n",
    "    it = 0\n",
    "    for dataset in datasets[:5]:\n",
    "\n",
    "        print(f'Evaluating dataset {it}', flush=True)\n",
    "        it+=1\n",
    "\n",
    "        data = dataset['data']\n",
    "        label = dataset['label'].max(axis=1) #label per pixel\n",
    "        \n",
    "        X = torch.tensor(data).float().to(device)\n",
    "\n",
    "        auc, loss = train_model(model, X, label, lr)\n",
    "        auc_epoch_list.append(auc)\n",
    "        loss_epoch_list.append(loss)\n",
    "\n",
    "        # auc_list.append(get_auc(scores, label).round(3))\n",
    "        # f1_list.append(best_f1score(scores, label).round(3))\n",
    "        # mcc_list.append(best_mcc(scores, label).round(3))\n",
    "\n",
    "    return np.mean(auc_epoch_list, axis=0).round(3), np.mean(loss_epoch_list, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.clone()\n",
    "\n",
    "X2 = X2.view(-1, X.shape[1], 1)\n",
    "\n",
    "dataset = TensorDataset(X2, X2)  # we want to reconstruct the same input\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Create an iterator\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "# Get the first batch\n",
    "batch_X, batch_y = next(data_iter)\n",
    "\n",
    "if model.n_features>1:\n",
    "    batch_X2 = batch_X.T.unsqueeze(0)\n",
    "\n",
    "print(batch_X.shape)\n",
    "print(batch_X2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.T.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_features': 2,\n",
    "                'latent_dim': 4,\n",
    "                'rnn_type': 'LSTM',\n",
    "                'rnn_act': 'relu',\n",
    "                'device': device}\n",
    "batch_size = 512\n",
    "\n",
    "model_class = getattr(models, 'RAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "model_params = {key: getattr(model, key) for key in relevant_params if hasattr(model, key)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "batch_size = 27\n",
    "seq_len = 10\n",
    "\n",
    "x = torch.tensor([])\n",
    "for i in range(seq_len):\n",
    "    x_i = i*torch.ones([batch_size, n_features])\n",
    "\n",
    "    if x_i.dim() == 1:\n",
    "        x = torch.cat([x, x_i.unsqueeze(0)], axis=1)\n",
    "    else:\n",
    "        x = torch.cat([x, x_i], axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(-1, seq_len, n_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params['n_features'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(root_dir+'/outputs/pixel_detection/HP_training/TR_AE.pkl')\n",
    "datasets = torch.load(dataset_path + 'Oslo/training/dataset.pt')\n",
    "input_dim = datasets[0]['data'].shape[1]\n",
    "\n",
    "dataset = datasets[9]\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "X = torch.tensor(data).float().to(device)\n",
    "\n",
    "px.imshow(dataset['label'], aspect='auto', width=600, title=f'Example: {label.sum():.3g} anomalous nodes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[9]\n",
    "print(dataset['metadata'])\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "X = torch.tensor(data).float().to(device)\n",
    "\n",
    "lr = study.best_params['lr']\n",
    "n_epochs = study.best_params['n_epochs']\n",
    "n_layers = study.best_params['n_layers']\n",
    "layer_dims = [input_dim]\n",
    "for i in range(n_layers):\n",
    "    layer_dims.append(study.best_params[f'layer_dim_{i}'])\n",
    "\n",
    "# dims = [177, 89, 49, 35, 17]\n",
    "# layer_dims = [input_dim, *dims]\n",
    "# lr = 0.000025\t\n",
    "# n_epochs = 261\n",
    "\n",
    "model = models.AE(layer_dims)\n",
    "model = model.to(device)\n",
    "\n",
    "rng_seed = 0\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "model.reset_parameters()\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# for epoch in range(1, 1+np.max(epochs_list)):\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, X)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    output_list.append(output)\n",
    "\n",
    "scores = pixel_mse(output_list[-1], X).detach().cpu().numpy()\n",
    "auc = get_auc(scores, label, resolution=101).round(3)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames\n",
    "df_X = pd.DataFrame(X.detach().cpu().numpy())\n",
    "df_output = pd.DataFrame(output_list[-1].detach().cpu().numpy())\n",
    "\n",
    "# Assign sensor IDs as index\n",
    "df_X.index.name = \"sensor_id\"\n",
    "df_output.index.name = \"sensor_id\"\n",
    "\n",
    "# Melt to long format\n",
    "df_X_long = df_X.reset_index().melt(id_vars=[\"sensor_id\"], var_name=\"timestamp\", value_name=\"X\")\n",
    "df_output_long = df_output.reset_index().melt(id_vars=[\"sensor_id\"], var_name=\"timestamp\", value_name=\"output\")\n",
    "\n",
    "# Merge both DataFrames\n",
    "df_final = pd.merge(df_X_long, df_output_long, on=[\"sensor_id\", \"timestamp\"])\n",
    "\n",
    "# Convert timestamp to integer (assuming column names were originally numbers)\n",
    "df_final[\"timestamp\"] = df_final[\"timestamp\"].astype(int)\n",
    "\n",
    "print(f'{np.where(label)[0]}')\n",
    "px.line(df_final, x='timestamp', y=['X','output'], animation_frame='sensor_id', width=1000, range_y=[-10,35]).show()\n",
    "\n",
    "\n",
    "fig = px.line(y=[label*scores.max()*0.75, scores], width=1000, markers=True)  # Add markers\n",
    "fig.update_traces(line=dict(width=0.5), marker={'size':5})  # Make line thin\n",
    "fig.show()\n",
    "\n",
    "px.line(df_final[df_final.sensor_id.isin(np.where(label)[0])], x='timestamp', y=['X','output'], animation_frame='sensor_id', width=1000, range_y=[-10,35]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = fd.NNGraph(pd.DataFrame(data=dataset['pos'], columns=['easting','northing']), radius=15)\n",
    "utils.plotly_signal(G, X[:,-1].cpu().numpy(), width=500, height=300)\n",
    "utils.plotly_signal(G, label, width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GCNencoder([15,12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_classes = [models.GCN2MLP, models.AE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(model, tuple(possible_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygsp.graphs.NNGraph(dataset['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = fd.NNGraph(pd.DataFrame(dataset['pos'], columns=['easting','northing']), radius=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['edge_weight'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(models, 'AE')([2, 2, 2, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsensors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
