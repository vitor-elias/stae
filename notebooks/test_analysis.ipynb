{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import contextily as cx\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import torch\n",
    "import joblib\n",
    "import calflops\n",
    "import time \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, auc, f1_score, matthews_corrcoef\n",
    "from calflops.flops_counter import calculate_flops\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn.cluster import KMeans\n",
    "from tsmoothie import LowessSmoother, ExponentialSmoother\n",
    "from pyprojroot import here\n",
    "from scipy.spatial import ConvexHull\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import source.nn.models as models\n",
    "import source.utils.utils as utils\n",
    "import source.utils.fault_detection as fd\n",
    "\n",
    "from source.utils.utils import roc_params, compute_auc, get_auc, best_mcc, best_f1score, otsuThresholding\n",
    "from source.utils.utils import synthetic_timeseries\n",
    "from source.utils.utils import plotly_signal\n",
    "\n",
    "from importlib import reload\n",
    "models = reload(models)\n",
    "utils = reload(utils)\n",
    "fd = reload(fd)\n",
    "\n",
    "from pyprojroot import here\n",
    "root_dir = str(here())\n",
    "\n",
    "insar_dir = os.path.expanduser('~/data/raw/')\n",
    "data_path = root_dir + '/data/interim/'\n",
    "dataset_path = root_dir + \"/data/datasets/\"\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'DejaVu Serif'})\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_{dataset_name}.pkl')\n",
    "\n",
    "model = 'GCNAE'\n",
    "\n",
    "print(model_dict[model]['trial_params'])\n",
    "print(model_dict[model]['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['GCNAE'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[model]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model_dict['GCNAE']['auc_evolution'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model_dict['GCNAE']['auc_evolution'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "# Dictionary to store metrics for each model\n",
    "metrics_dict = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Computing metrics for {model_name}\")\n",
    "    auc_list = []\n",
    "    f1_list = []\n",
    "    mcc_list = []\n",
    "    \n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        # Compute metrics for each dataset based on each label being true if any anomaly is present\n",
    "        label = dataset['label'].any(axis=1)\n",
    "        scores = model_dict[model_name]['scores'][idx]\n",
    "        \n",
    "        auc = get_auc(scores, label, resolution=101).round(3)\n",
    "        f1 = best_f1score(scores, label).round(3)\n",
    "        mcc = best_mcc(scores, label).round(3)\n",
    "        \n",
    "        auc_list.append(auc)\n",
    "        f1_list.append(f1)\n",
    "        mcc_list.append(mcc)\n",
    "    \n",
    "    # Store metrics and compute statistics\n",
    "    metrics_dict[model_name] = {\n",
    "        'aucs': auc_list,\n",
    "        'f1s': f1_list,\n",
    "        'mccs': mcc_list,\n",
    "        'mean_auc': np.mean(auc_list).round(3),\n",
    "        'mean_f1': np.mean(f1_list).round(3),\n",
    "        'mean_mcc': np.mean(mcc_list).round(3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    auc_list = metrics_dict[model_name]['aucs']\n",
    "    mean_auc = metrics_dict[model_name]['mean_auc']\n",
    "    mean_f1 = metrics_dict[model_name]['mean_f1']\n",
    "    mean_mcc = metrics_dict[model_name]['mean_mcc']\n",
    "    \n",
    "    # Calculate means for Malmo (first 72) and Oslo (last 72)\n",
    "    malmo_mean = np.mean(auc_list[:72]).round(3)\n",
    "    oslo_mean = np.mean(auc_list[-72:]).round(3)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Training Mean: {model_dict[model_name]['auc']}\")\n",
    "    print(f\"  Test AUC: {mean_auc}\")\n",
    "    print(f\"  Test F1: {mean_f1}\")\n",
    "    print(f\"  Test MCC: {mean_mcc}\")\n",
    "    print(f\"  Test (MalmÃ¶): {malmo_mean}\")\n",
    "    print(f\"  Test (Oslo): {oslo_mean}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_accuracy(metric, labels, interp=True):\n",
    "    label = labels.any(axis=1)\n",
    "    \n",
    "    thr_list = list(np.linspace(metric.min(), metric.max(),101))\n",
    "\n",
    "    f1score = []\n",
    "    for threshold in thr_list[0:-1]:\n",
    "        y = (metric>threshold)\n",
    "        f1score.append(f1_score(label, y))\n",
    "\n",
    "    label_1 = (labels==1).any(axis=1)\n",
    "    label_2 = (labels==2).any(axis=1)\n",
    "\n",
    "    thr_max = thr_list[np.argmax(f1score)]\n",
    "    detections = (metric>thr_max)\n",
    "    \n",
    "    # Calculate accuracy for label_1\n",
    "    true_positives = np.sum(detections & label_1)\n",
    "    total_label_1 = np.sum(label_1)\n",
    "    accuracy_label_1 = true_positives / total_label_1 if total_label_1 > 0 else 0\n",
    "\n",
    "    # Calculate accuracy for label_2\n",
    "    true_positives = np.sum(detections & label_2)\n",
    "    total_label_2 = np.sum(label_2)\n",
    "    accuracy_label_2 = true_positives / total_label_2 if total_label_2 > 0 else 0   \n",
    "    \n",
    "    return accuracy_label_1, accuracy_label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Geological_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "# Dictionary to store metrics for each model\n",
    "metrics_dict = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Computing metrics for {model_name}\")\n",
    "    acc1_list = []\n",
    "    acc2_list = []\n",
    "    \n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        # Compute metrics for each dataset based on each label being true if any anomaly is present\n",
    "        scores = model_dict[model_name]['scores'][idx]\n",
    "        \n",
    "        acc1, acc2 = label_accuracy(scores, dataset['label'])\n",
    "        acc1_list.append(acc1)\n",
    "        acc2_list.append(acc2)\n",
    "    \n",
    "    # Store metrics and compute statistics\n",
    "    metrics_dict[model_name] = {\n",
    "        'acc1s': acc1_list,\n",
    "        'acc2s': acc2_list,\n",
    "        'mean_acc1': np.mean(acc1_list).round(3),\n",
    "        'mean_acc2': np.mean(acc2_list).round(3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    print(f\"{model_name:<10}: - Geo: {metrics_dict[model_name]['mean_acc1']:<5}, Phase: {metrics_dict[model_name]['mean_acc2']:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Test/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Testing/model_dict_testing_{dataset_name}.pkl')\n",
    "\n",
    "dataset = datasets[0]\n",
    "labels = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels==1).any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_dict['AE']['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(datasets[0]['label'].max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0]['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig = copy.deepcopy(model_dict['AE']['model'])\n",
    "\n",
    "# Modify input layer size\n",
    "model_orig.encoder[0].in_features = 300  # new input size\n",
    "model_orig.encoder[0].weight = torch.nn.Parameter(torch.randn(25, 300))  # new weight matrix\n",
    "model_orig.encoder[0].bias = torch.nn.Parameter(torch.randn(25))  # new bias vector\n",
    "\n",
    "# Modify output layer size\n",
    "model_orig.decoder[-1].out_features = 300  # new output size\n",
    "model_orig.decoder[-1].weight = torch.nn.Parameter(torch.randn(300, 25))  # new weight matrix\n",
    "model_orig.decoder[-1].bias = torch.nn.Parameter(torch.randn(300))  # new bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RAE_GRU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.split('_')[-1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['GUNet']['trial_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[150] + [model_dict['AE']['trial_params'][f'layer_dim_{i}'] for i in range(model_dict['AE']['trial_params']['n_layers'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "new_model_params = {key: getattr(model, key) for key in relevant_params}\n",
    "new_model_params['n_features'] = X.shape[0]\n",
    "model = models.RAE(**new_model_params)\n",
    "model.to(new_model_params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['AE']['model'].decoder[-1].out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_{dataset_name}.pkl')\n",
    "model_dict['AE'].keys()\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "# Base x locations\n",
    "x = np.arange(len(model_names))\n",
    "x_positions = 2*(x)\n",
    "\n",
    "# Extract num_parameters and total_params from model_dict\n",
    "num_parameters = [model_dict[model]['num_parameters'] for model in model_names]\n",
    "total_params = [model_dict[model]['num_parameters'] * model_dict[model]['trial_params']['n_epochs'] for model in model_names]\n",
    "\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for num_parameters\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions - bar_width / 2,\n",
    "    y=num_parameters,\n",
    "    width=bar_width,\n",
    "    name='Count of Trainable Parameters',\n",
    "    text=num_parameters,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Add bars for total_params\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions + bar_width / 2,\n",
    "    y=total_params,\n",
    "    width=bar_width,\n",
    "    name='Count of Parameter Updates',\n",
    "    text=total_params,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[m.replace('_','') for m in model_names],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickformat=\"~s\",\n",
    "        tickvals=[i*1000 for i in range(0, 1001, 100)],  # Example: 0k, 100k, 200k, ..., 1000k\n",
    "    ),\n",
    "    barmode='group',\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        x=0.02,  # Horizontal position of the legend\n",
    "        y=0.95,  # Vertical position of the legend\n",
    "        bgcolor='rgba(255,255,255,0.5)',  # Semi-transparent background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\",\n",
    "        size=18\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/complexity_parameters_EGMS.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Geological_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "# Base x locations\n",
    "x = np.arange(len(model_names))\n",
    "x_positions = 2*(x)\n",
    "\n",
    "# Extract num_parameters and total_params from model_dict\n",
    "num_parameters = [model_dict[model]['num_parameters'] for model in model_names]\n",
    "total_params = [model_dict[model]['num_parameters'] * model_dict[model]['trial_params']['n_epochs'] for model in model_names]\n",
    "\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for num_parameters\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions - bar_width / 2,\n",
    "    y=num_parameters,\n",
    "    width=bar_width,\n",
    "    name='Count of Trainable Parameters',\n",
    "    text=num_parameters,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Add bars for total_params\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_positions + bar_width / 2,\n",
    "    y=total_params,\n",
    "    width=bar_width,\n",
    "    name='Count of Parameter Updates',\n",
    "    text=total_params,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[m.replace('_','') for m in model_names],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickformat=\"~s\",\n",
    "        tickvals=[i*1000 for i in range(0, 1001, 100)],  # Example: 0k, 100k, 200k, ..., 1000k\n",
    "    ),\n",
    "    barmode='group',\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        x=0.02,  # Horizontal position of the legend\n",
    "        y=0.95,  # Vertical position of the legend\n",
    "        bgcolor='rgba(255,255,255,0.5)',  # Semi-transparent background\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\",\n",
    "        size=18\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir + f'/outputs/figs/complexity_parameters_Geological.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN Epoch_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'EGMS_anomaly'\n",
    "datasets = torch.load(dataset_path + f'{dataset_name}/Training/dataset.pt')\n",
    "model_dict = torch.load(root_dir + f'/outputs/Optuna_analysis/model_dict_times_{dataset_name}.pkl')\n",
    "\n",
    "model_names = ['AE', 'GCN2MLP', 'GCNAE', 'GConv2MLP', 'GConvAE', 'GUNet', 'RAE_GRU', 'RAE_LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'time_epoch'\n",
    "\n",
    "mean_times = {model: np.mean(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "std_times = {model: np.std(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "\n",
    "for model in model_names:\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  Epoch time: {mean_times[model]:.3f} +- {std_times[model]:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'time_total'\n",
    "\n",
    "mean_times = {model: np.mean(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "std_times = {model: np.std(np.mean(model_dict[model][var], axis=1)) for model in model_names}\n",
    "\n",
    "for model in model_names:\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  Total time: {mean_times[model]:.3f} +- {std_times[model]:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_dict['AE']['model'].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model_dict['AE']['time_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_info in model_dict.items():\n",
    "    print(f\"{model_name}: {model_info['trial_params']['n_epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "dataset_path = root_dir + \"/data/datasets/\"\n",
    "datafile = 'EGMS_anomaly/Training/dataset.pt'\n",
    "datasets = torch.load(dataset_path + datafile)\n",
    "\n",
    "dataset = datasets[0]\n",
    "input_dim = datasets[0]['data'].shape[1]\n",
    "\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "\n",
    "X = torch.tensor(data).float().to( device )\n",
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_features': 2,\n",
    "                'latent_dim': 4,\n",
    "                'rnn_type': 'GRU',\n",
    "                'rnn_act': 'relu',\n",
    "                'device': device}\n",
    "batch_size = 512\n",
    "\n",
    "model_class = getattr(models, 'RAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if isinstance(model, models.RAE) and (model.n_features != 1):\n",
    "    relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "    new_model_params = {key: getattr(model, key) for key in relevant_params}\n",
    "    new_model_params['n_features'] = X.shape[0]\n",
    "    model = models.RAE(**new_model_params)\n",
    "    model.to(new_model_params['device'])\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'layer_dims':[input_dim, 4, 4]}\n",
    "\n",
    "model_class = getattr(models, 'GConvAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'layer_dims':[input_dim, 4, 4]}\n",
    "\n",
    "model_class = getattr(models, 'GCNAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'in_channels': input_dim,\n",
    "                'out_channels': input_dim,\n",
    "                'hidden_channels': 300,\n",
    "                'depth': 1,\n",
    "                'pool_ratios': 0.7}\n",
    "\n",
    "model_class = getattr(models, 'GUNet')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_params}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_mse(output,X):\n",
    "    point_mse = torch.nn.MSELoss(reduction='none')\n",
    "    return torch.mean(point_mse(output,X), axis=1)\n",
    "\n",
    "\n",
    "device = 'cuda:2'\n",
    "def train_model(model, X, label, lr, G=None):\n",
    "\n",
    "    rng_seed = 0\n",
    "    torch.manual_seed(rng_seed)\n",
    "    torch.cuda.manual_seed(rng_seed)\n",
    "    np.random.seed(rng_seed)\n",
    "\n",
    "    loss_epoch = []\n",
    "    auc_epoch = []\n",
    "    scores_epoch = []\n",
    "\n",
    "    if G is not None:\n",
    "        A = torch.tensor(G.W.toarray()).float()\n",
    "        A = A.to(device)    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    def pixel_mse(output,X):\n",
    "        point_mse = torch.nn.MSELoss(reduction='none')\n",
    "        return torch.mean(point_mse(output,X), axis=1)\n",
    "\n",
    "    model.train()\n",
    "    model.reset_parameters()\n",
    "\n",
    "    # for epoch in range(1, 1+np.max(epochs_list)):\n",
    "    for epoch in range(1,1000):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        if epoch in np.ceil(np.geomspace(1,1000,10)):\n",
    "\n",
    "\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            scores = pixel_mse(output, X).detach().cpu().numpy()\n",
    "            # scores_epoch.append(scores)\n",
    "\n",
    "            auc = get_auc(scores, label, resolution=101).round(3)\n",
    "            auc_epoch.append(auc)\n",
    "\n",
    "\n",
    "        # if epoch in epochs_list:\n",
    "        #     S_partials.append(S)...\n",
    "\n",
    "    return auc_epoch, loss_epoch\n",
    "\n",
    "def evaluate_model(model, datasets, lr):\n",
    "\n",
    "    auc_epoch_list = []\n",
    "    loss_epoch_list = []\n",
    "\n",
    "    it = 0\n",
    "    for dataset in datasets[:5]:\n",
    "\n",
    "        print(f'Evaluating dataset {it}', flush=True)\n",
    "        it+=1\n",
    "\n",
    "        data = dataset['data']\n",
    "        label = dataset['label'].max(axis=1) #label per pixel\n",
    "        \n",
    "        X = torch.tensor(data).float().to(device)\n",
    "\n",
    "        auc, loss = train_model(model, X, label, lr)\n",
    "        auc_epoch_list.append(auc)\n",
    "        loss_epoch_list.append(loss)\n",
    "\n",
    "        # auc_list.append(get_auc(scores, label).round(3))\n",
    "        # f1_list.append(best_f1score(scores, label).round(3))\n",
    "        # mcc_list.append(best_mcc(scores, label).round(3))\n",
    "\n",
    "    return np.mean(auc_epoch_list, axis=0).round(3), np.mean(loss_epoch_list, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.clone()\n",
    "\n",
    "X2 = X2.view(-1, X.shape[1], 1)\n",
    "\n",
    "dataset = TensorDataset(X2, X2)  # we want to reconstruct the same input\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Create an iterator\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "# Get the first batch\n",
    "batch_X, batch_y = next(data_iter)\n",
    "\n",
    "if model.n_features>1:\n",
    "    batch_X2 = batch_X.T.unsqueeze(0)\n",
    "\n",
    "print(batch_X.shape)\n",
    "print(batch_X2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.T.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_features': 2,\n",
    "                'latent_dim': 4,\n",
    "                'rnn_type': 'LSTM',\n",
    "                'rnn_act': 'relu',\n",
    "                'device': device}\n",
    "batch_size = 512\n",
    "\n",
    "model_class = getattr(models, 'RAE')\n",
    "model = model_class(**model_params)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_params = ['n_features', 'latent_dim', 'rnn_type', 'rnn_act', 'device']\n",
    "model_params = {key: getattr(model, key) for key in relevant_params if hasattr(model, key)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "batch_size = 27\n",
    "seq_len = 10\n",
    "\n",
    "x = torch.tensor([])\n",
    "for i in range(seq_len):\n",
    "    x_i = i*torch.ones([batch_size, n_features])\n",
    "\n",
    "    if x_i.dim() == 1:\n",
    "        x = torch.cat([x, x_i.unsqueeze(0)], axis=1)\n",
    "    else:\n",
    "        x = torch.cat([x, x_i], axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(-1, seq_len, n_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params['n_features'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(root_dir+'/outputs/pixel_detection/HP_training/TR_AE.pkl')\n",
    "datasets = torch.load(dataset_path + 'Oslo/training/dataset.pt')\n",
    "input_dim = datasets[0]['data'].shape[1]\n",
    "\n",
    "dataset = datasets[9]\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "X = torch.tensor(data).float().to(device)\n",
    "\n",
    "px.imshow(dataset['label'], aspect='auto', width=600, title=f'Example: {label.sum():.3g} anomalous nodes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[9]\n",
    "print(dataset['metadata'])\n",
    "data = dataset['data']\n",
    "label = dataset['label'].max(axis=1) #label per pixel\n",
    "X = torch.tensor(data).float().to(device)\n",
    "\n",
    "lr = study.best_params['lr']\n",
    "n_epochs = study.best_params['n_epochs']\n",
    "n_layers = study.best_params['n_layers']\n",
    "layer_dims = [input_dim]\n",
    "for i in range(n_layers):\n",
    "    layer_dims.append(study.best_params[f'layer_dim_{i}'])\n",
    "\n",
    "# dims = [177, 89, 49, 35, 17]\n",
    "# layer_dims = [input_dim, *dims]\n",
    "# lr = 0.000025\t\n",
    "# n_epochs = 261\n",
    "\n",
    "model = models.AE(layer_dims)\n",
    "model = model.to(device)\n",
    "\n",
    "rng_seed = 0\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "model.reset_parameters()\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# for epoch in range(1, 1+np.max(epochs_list)):\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, X)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    output_list.append(output)\n",
    "\n",
    "scores = pixel_mse(output_list[-1], X).detach().cpu().numpy()\n",
    "auc = get_auc(scores, label, resolution=101).round(3)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames\n",
    "df_X = pd.DataFrame(X.detach().cpu().numpy())\n",
    "df_output = pd.DataFrame(output_list[-1].detach().cpu().numpy())\n",
    "\n",
    "# Assign sensor IDs as index\n",
    "df_X.index.name = \"sensor_id\"\n",
    "df_output.index.name = \"sensor_id\"\n",
    "\n",
    "# Melt to long format\n",
    "df_X_long = df_X.reset_index().melt(id_vars=[\"sensor_id\"], var_name=\"timestamp\", value_name=\"X\")\n",
    "df_output_long = df_output.reset_index().melt(id_vars=[\"sensor_id\"], var_name=\"timestamp\", value_name=\"output\")\n",
    "\n",
    "# Merge both DataFrames\n",
    "df_final = pd.merge(df_X_long, df_output_long, on=[\"sensor_id\", \"timestamp\"])\n",
    "\n",
    "# Convert timestamp to integer (assuming column names were originally numbers)\n",
    "df_final[\"timestamp\"] = df_final[\"timestamp\"].astype(int)\n",
    "\n",
    "print(f'{np.where(label)[0]}')\n",
    "px.line(df_final, x='timestamp', y=['X','output'], animation_frame='sensor_id', width=1000, range_y=[-10,35]).show()\n",
    "\n",
    "\n",
    "fig = px.line(y=[label*scores.max()*0.75, scores], width=1000, markers=True)  # Add markers\n",
    "fig.update_traces(line=dict(width=0.5), marker={'size':5})  # Make line thin\n",
    "fig.show()\n",
    "\n",
    "px.line(df_final[df_final.sensor_id.isin(np.where(label)[0])], x='timestamp', y=['X','output'], animation_frame='sensor_id', width=1000, range_y=[-10,35]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = fd.NNGraph(pd.DataFrame(data=dataset['pos'], columns=['easting','northing']), radius=15)\n",
    "utils.plotly_signal(G, X[:,-1].cpu().numpy(), width=500, height=300)\n",
    "utils.plotly_signal(G, label, width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GCNencoder([15,12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_classes = [models.GCN2MLP, models.AE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(model, tuple(possible_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygsp.graphs.NNGraph(dataset['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = fd.NNGraph(pd.DataFrame(dataset['pos'], columns=['easting','northing']), radius=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['edge_weight'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(models, 'AE')([2, 2, 2, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsensors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
