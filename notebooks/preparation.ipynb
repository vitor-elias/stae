{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import torch\n",
    "import optuna\n",
    "import joblib\n",
    "import pickle\n",
    "import tifffile\n",
    "import nibabel\n",
    "import scipy.io\n",
    "import pygsp\n",
    "import scipy.ndimage\n",
    "import pyod\n",
    "import warnings\n",
    "import hashlib\n",
    "import sqlite3\n",
    "\n",
    "from scipy.stats import entropy, kurtosis, skew\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from sklearn.cluster import KMeans, BisectingKMeans, SpectralClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.kpca import KPCA\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import Linear, Conv1d, LayerNorm, DataParallel, ReLU, Sequential, Parameter\n",
    "from torch_geometric.nn.dense import mincut_pool, dense_mincut_pool\n",
    "from torch_geometric.datasets import AttributedGraphDataset\n",
    "from torch_geometric.utils import to_networkx, subgraph, to_dense_adj\n",
    "\n",
    "import source.nn.models as models\n",
    "import source.utils.utils as utils\n",
    "import source.utils.fault_detection as fd\n",
    "\n",
    "from source.utils.utils import roc_params, compute_auc, get_auc, best_mcc, best_f1score, otsuThresholding\n",
    "from source.utils.utils import synthetic_timeseries\n",
    "from source.utils.utils import plotly_signal\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "models = reload(models)\n",
    "utils = reload(utils)\n",
    "\n",
    "from pyprojroot import here\n",
    "root_dir = str(here())\n",
    "\n",
    "data_dir = os.path.expanduser('~/data/interim/')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'DejaVu Serif'})\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_anomaly(node_positions, num_timestamps, anomaly_radius, onset, transient, sigma_decay=3):\n",
    "\n",
    "    num_nodes = node_positions.shape[0]\n",
    "    selected_nodes, anomaly_center = utils.select_radius(node_positions, anomaly_radius)\n",
    "\n",
    "    distances = np.linalg.norm(node_positions - anomaly_center, axis=1)\n",
    "    sigma = distances[selected_nodes[-1]]/sigma_decay\n",
    "    diff = node_positions - anomaly_center\n",
    "\n",
    "    anomaly = np.exp(- (diff[:,0]**2)/(2*sigma**2) - (diff[:,1]**2)/(2*sigma**2))\n",
    "\n",
    "    onset_index = int(onset*num_timestamps)\n",
    "\n",
    "    label = np.zeros((num_nodes, num_timestamps))\n",
    "    label[selected_nodes, onset_index:] = 1\n",
    "\n",
    "    transient_matrix = np.tile(np.arange(num_timestamps), (num_nodes, 1))\n",
    "\n",
    "    transient_matrix = (transient_matrix - onset_index)/transient\n",
    "    transient_matrix = transient_matrix*label\n",
    "    transient_matrix[transient_matrix>1] = 1\n",
    "\n",
    "    anomaly_matrix = transient_matrix*np.tile(anomaly.reshape((-1,1)), (1, num_timestamps))\n",
    "\n",
    "    return anomaly_matrix, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df_StOlavs_D1L2B'\n",
    "df_orig = pd.read_parquet(data_dir + f'{dataset}.parq')\n",
    "\n",
    "df_ds = df_orig[df_orig.timestamp<'2022-06'].copy()\n",
    "\n",
    "df_ds = df_ds.groupby('pid').resample('30d', on='timestamp').mean().reset_index()\n",
    "\n",
    "df, nodes = fd.treat_nodes(df_ds)\n",
    "_, nodes['subgraph'] = fd.NNGraph(nodes, radius=15, subgraphs=True)\n",
    "\n",
    "main_graph = nodes.subgraph.value_counts().index[0]\n",
    "nodes = nodes.query('subgraph==@main_graph').copy()\n",
    "G = fd.NNGraph(nodes, radius=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "N = 200\n",
    "T = 20\n",
    "G = pygsp.graphs.Grid2d(N)\n",
    "anomaly, label = add_anomaly(G.coords, T, 0.2, 0, 10, 2)\n",
    "px.imshow(anomaly.reshape((N,N,T)), animation_frame=2, aspect='auto', \n",
    "            range_color=[anomaly.min(), anomaly.max()], width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_nodes = 500\n",
    "coords = G.coords\n",
    "offset = coords.min(axis=0)\n",
    "\n",
    "ranges = (coords - offset).max(axis=0)\n",
    "\n",
    "# Generate a random location within the bounding box\n",
    "start_coords = offset + np.random.uniform([0.05*ranges[0], 0.05*ranges[1]], [0.95*ranges[0], 0.95*ranges[1]])\n",
    "print(offset)\n",
    "print(start_coords)\n",
    "\n",
    "distances = np.linalg.norm(coords - start_coords, axis=1)\n",
    "\n",
    "selected_nodes = np.argsort(distances)[:Number_of_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = distances[selected_nodes[-1]]/3\n",
    "diff = coords - start_coords\n",
    "\n",
    "anomaly = 100*np.exp(- (diff[:,0]**2)/(2*sigma**2) - (diff[:,1]**2)/(2*sigma**2))\n",
    "\n",
    "signal = np.zeros((G.N,))\n",
    "signal[selected_nodes] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_signal(G, signal, width=600, height=500)\n",
    "plotly_signal(G, anomaly*signal, width=600, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nodes = select_radius(G.coords, 40)[0]\n",
    "len(selected_nodes)\n",
    "\n",
    "signal = np.zeros((G.N,))\n",
    "signal[selected_nodes] = 1\n",
    "plotly_signal(G, signal, width=600, height=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix, label = geological_events(G.coords, 20, 50, 0.25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(label.max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_matrix[3312,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.reshape((100,100,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_signal(G, data_matrix[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(anomaly.reshape((-1,1)), (1, num_timestamps)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transient_matrix*(anomaly.reshape(10000,1))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 6\n",
    "num_timestamps = 10\n",
    "onset = 0.5\n",
    "transient = 3\n",
    "\n",
    "onset_index = int(onset*num_timestamps)\n",
    "\n",
    "transient_matrix = np.tile(np.arange(num_timestamps), (num_nodes, 1))\n",
    "\n",
    "transient_matrix = (transient_matrix - onset_index)/transient\n",
    "transient_matrix = transient_matrix*label\n",
    "transient_matrix[transient_matrix>1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = np.random.rand(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient_matrix*anomaly.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1,6)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geological_events(G.coords, 10, 50, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros((5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(22.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(0.25*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[selected_nodes, 3:] = 1\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nodes = np.array((1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_VR = pd.read_parquet(root_dir+'/outputs/testing_mincut/df_locality_VR.parq').drop(['DR'],axis=1)\n",
    "df_test_DR = pd.read_parquet(root_dir+'/outputs/testing_mincut/df_locality_DR.parq').drop(['VR'],axis=1)\n",
    "df_means_VR = df_test_VR.groupby('bin', as_index=False).mean().rename({'VR':'Var'}, axis=1)\n",
    "df_means_VR['Varname'] = 'VR'\n",
    "df_means_DR = df_test_DR.groupby('bin', as_index=False).mean().rename({'DR':'Var'}, axis=1)\n",
    "df_means_DR['Varname'] = 'DR'\n",
    "df = pd.concat([df_means_VR, df_means_DR])\n",
    "df_long = df.melt(id_vars=['Var', 'Varname'], value_vars=['AUC', 'F1 score', 'MCC'],\n",
    "                  var_name='Metric', value_name='Value')\n",
    "\n",
    "fig = px.scatter(df_long, x='Var', y='Value', color='Metric', facet_col='Varname',\n",
    "                 trendline='lowess', height=400, width=1000, template='plotly_white')\n",
    "\n",
    "# Customize x-axis labels for each facet\n",
    "fig.update_xaxes(matches=None)  # Allow each x-axis to be edited separately\n",
    "\n",
    "# Set custom x-axis titles for each facet\n",
    "fig.update_xaxes(title_text=\"VR\", col=1, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black')  \n",
    "fig.update_xaxes(title_text=\"DR\", col=2, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.update_yaxes(range=[0.2,1], col=1, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.update_yaxes(range=[0.2,1], col=2, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "fig.update_layout(font =dict(family=\"Times New Roman\", size=22),\n",
    "                  plot_bgcolor = 'rgba(0, 0, 0, 0)',\n",
    "                  paper_bgcolor = 'rgba(0, 0, 0, 0)',\n",
    "                  legend=dict(x=0.65,\n",
    "                              y=0.45,\n",
    "                              xanchor=\"right\",\n",
    "                              yanchor=\"top\",\n",
    "                              bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
    "                            ),\n",
    "                  margin=dict(l=20, r=20, t=1, b=40)\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir+'/outputs/figs/TPAMI/locality_synthetic.png')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Spill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_partials_list = []\n",
    "label_list = []\n",
    "shape_list = []\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for im in range(1,19):\n",
    "\n",
    "    mat = scipy.io.loadmat(data_dir+f'HSIoil/GM{im:02}.mat')\n",
    "    downsample_factor = 0.1\n",
    "    map = scipy.ndimage.zoom(mat['map'], zoom=downsample_factor, order=3)\n",
    "    data_orig = scipy.ndimage.zoom(mat['img'], zoom=(downsample_factor, downsample_factor, 1), order=3)\n",
    "    X = data_orig.reshape(data_orig.shape[0]*data_orig.shape[1],data_orig.shape[2])\n",
    "    # X = torch.tensor(X.astype(np.float32)).float()\n",
    "\n",
    "    metadata = {'samples':1,\n",
    "                'id':im,\n",
    "                'N':X.shape[0],\n",
    "                'T':X.shape[1],\n",
    "                'downsample':downsample_factor\n",
    "                }\n",
    "\n",
    "    print(im)\n",
    "\n",
    "    G = pygsp.graphs.Grid2d(data_orig.shape[0],data_orig.shape[1])\n",
    "\n",
    "    dataset = {'data':[X], 'labels':[map.reshape(-1,)], 'G':G, 'metadata':metadata}\n",
    "    datasets.append(dataset)\n",
    "\n",
    "    # coords = G.coords\n",
    "    # A = G.W.toarray()\n",
    "    # idx = np.lexsort((-coords[:, 1], coords[:, 0]))\n",
    "    # A = torch.tensor(A[np.ix_(idx,idx)]).float()\n",
    "    # A = A.to(device)\n",
    "\n",
    "    # n_timestamps = X.shape[1]\n",
    "    # n_clusters = 5\n",
    "    # n_extra_feats = 0\n",
    "    # weight_loss = 1\n",
    "\n",
    "    # model = models.ClusterTS(n_timestamps, n_clusters, n_extra_feats)\n",
    "    # model = model.to(device)\n",
    "\n",
    "    # epochs_list = [1,25,50,100,200,500,1000]\n",
    "    # S_partials, lmc, lo = train_cluster(epochs_list, model, X, G, device, weight_loss)\n",
    "    # S_partials_list.append(S_partials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:2'\n",
    "study = joblib.load(root_dir+f'/outputs/HP_training/SB_MC.pkl')\n",
    "best_params = study.best_params\n",
    "model = models.ClusterTS(metadata['T'], n_clusters=best_params['n_clusters'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_locality(model, datasets,\n",
    "                        epochs=best_params['N_epochs'],\n",
    "                        weight_loss=best_params['weight_loss'],\n",
    "                        lr=best_params['lr'],\n",
    "                        skewth=best_params['skewth'],\n",
    "                        device=device\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_parquet(root_dir+'/outputs/testing_mincut/df_locality_OIL.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_test, x='VR', y='AUC', trendline='lowess').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.melt(id_vars=['sample_id','AUC','F1 score', 'MCC'],\n",
    "                  value_vars=['VR','DR'], var_name='Varname', value_name='Var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.melt(id_vars=['sample_id','AUC','F1 score', 'MCC'],\n",
    "                  value_vars=['VR','DR'], var_name='Varname', value_name='Var')\n",
    "df_long = df.melt(id_vars=['Var', 'Varname'], value_vars=['AUC', 'F1 score', 'MCC'],\n",
    "                  var_name='Metric', value_name='Value')\n",
    "\n",
    "fig = px.scatter(df_long, x='Var', y='Value', color='Metric', facet_col='Varname',\n",
    "                 trendline='lowess', height=400, width=1000, template='plotly_white')\n",
    "\n",
    "# Customize x-axis labels for each facet\n",
    "fig.update_xaxes(matches=None)  # Allow each x-axis to be edited separately\n",
    "\n",
    "# Set custom x-axis titles for each facet\n",
    "fig.update_xaxes(title_text=\"VR\", col=1, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black')  \n",
    "fig.update_xaxes(title_text=\"DR\", col=2, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.update_yaxes(range=[0.2,1], col=1, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.update_yaxes(range=[0.2,1], col=2, row=1, showline=True, mirror='allticks', linewidth=1, linecolor='black') \n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "fig.update_layout(font =dict(family=\"Times New Roman\", size=22),\n",
    "                  plot_bgcolor = 'rgba(0, 0, 0, 0)',\n",
    "                  paper_bgcolor = 'rgba(0, 0, 0, 0)',\n",
    "                  legend=dict(x=0.65,\n",
    "                              y=0.45,\n",
    "                              xanchor=\"right\",\n",
    "                              yanchor=\"top\",\n",
    "                              bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
    "                            ),\n",
    "                  margin=dict(l=20, r=20, t=1, b=40)\n",
    ")\n",
    "\n",
    "fig.write_image(root_dir+'/outputs/figs/TPAMI/locality_Oil.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(root_dir+'/outputs/testing_mincut/df_locality_OIL.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "axes = axes.ravel()  # Flatten the 3x6 grid into a 1D array for easy indexing\n",
    "\n",
    "# Iterate through images and DataFrame rows\n",
    "for idx in range(1, 19):\n",
    "    # Load the image\n",
    "    mat = scipy.io.loadmat(data_dir + f'HSIoil/GM{idx:02}.mat')\n",
    "    image = mat['map']\n",
    "\n",
    "    # Get the row corresponding to the current image id\n",
    "    row = df_test[df_test['id'] == idx].iloc[0]\n",
    "\n",
    "    # Plot the image on the left side of the cell\n",
    "    ax = axes[idx - 1]\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display metrics on the right side of the cell\n",
    "    ax.text(1.05, 0.5, \n",
    "            f\"VR: {row['VR']:.2f}\\n\"\n",
    "            f\"DR: {row['DR']:.2f}\\n\"\n",
    "            f\"AUC: {row['AUC']:.2f}\\n\"\n",
    "            f\"F1 score: {row['F1 score']:.2f}\\n\"\n",
    "            f\"MCC: {row['MCC']:.2f}\",\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='center',\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "heights, widths = [], []\n",
    "for im in range(1, 19):\n",
    "    mat = scipy.io.loadmat(data_dir + f'HSIoil/GM{im:02}.mat')\n",
    "    image = mat['map']\n",
    "    heights.append(image.shape[0])\n",
    "    widths.append(image.shape[1])\n",
    "\n",
    "avg_height = int(np.mean(heights))\n",
    "avg_width = int(np.mean(widths))\n",
    "\n",
    "# Step 2: Create the plot with 3 rows and 6 columns\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "axes = axes.ravel()  # Flatten the 3x6 grid into a 1D array for easy indexing\n",
    "\n",
    "# Step 3: Load each image, resize it, and plot with metrics\n",
    "for idx in range(1, 19):\n",
    "    # Load and resize the image\n",
    "    mat = scipy.io.loadmat(data_dir + f'HSIoil/GM{idx:02}.mat')\n",
    "    image = mat['map']\n",
    "    image_resized = np.array(Image.fromarray(image).resize((avg_width, avg_height)))\n",
    "\n",
    "    # Get the corresponding row in df_test\n",
    "    row = df_test[df_test['id'] == idx].iloc[0]\n",
    "\n",
    "    # Plot the image on the left side of the cell\n",
    "    ax = axes[idx - 1]\n",
    "    ax.imshow(image_resized, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the metrics text on the right side of the cell\n",
    "    metrics_text = (f\"VR: {row['VR']:.2f}\\n\"\n",
    "                    f\"DR: {row['DR']:.2f}\\n\\n\"\n",
    "                    f\"AUC: {row['AUC']:.2f}\\n\"\n",
    "                    f\"F1 score: {row['F1 score']:.2f}\\n\"\n",
    "                    f\"MCC: {row['MCC']:.2f}\")\n",
    "\n",
    "    ax.text(1.05, 0.5, metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='center',\n",
    "            fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load your DataFrame with columns: 'id', 'VR', 'DR', 'AUC', 'F1', and 'MCC'\n",
    "# Assuming `df_test` is already defined as per your description\n",
    "\n",
    "# Step 1: Sort the DataFrame by VR in ascending order\n",
    "df_test_sorted = df_test.sort_values(by='VR').reset_index(drop=True)\n",
    "\n",
    "# Step 2: Calculate the average height and width of the images\n",
    "heights, widths = [], []\n",
    "for im in range(1, 19):\n",
    "    mat = scipy.io.loadmat(data_dir + f'HSIoil/GM{im:02g}.mat')\n",
    "    image = mat['map']\n",
    "    heights.append(image.shape[0])\n",
    "    widths.append(image.shape[1])\n",
    "\n",
    "avg_height = int(np.mean(heights))\n",
    "avg_width = int(np.mean(widths))\n",
    "\n",
    "# Step 3: Create the plot with 3 rows and 6 columns\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "axes = axes.ravel()  # Flatten the 3x6 grid into a 1D array for easy indexing\n",
    "\n",
    "# Step 4: Load each image based on sorted VR, resize it, and plot with metrics\n",
    "for idx, row in df_test_sorted.iterrows():\n",
    "    # Load and resize the image\n",
    "    mat = scipy.io.loadmat(data_dir + f'HSIoil/GM{row[\"id\"]:02g}.mat')\n",
    "    image = mat['map']\n",
    "    image_resized = np.array(Image.fromarray(image).resize((avg_width, avg_height)))\n",
    "\n",
    "    # Plot the image on the left side of the cell\n",
    "    ax = axes[idx]\n",
    "    ax.imshow(image_resized, cmap='viridis')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the metrics text on the right side of the cell\n",
    "    metrics_text = (f\"VR: {row['VR']:.2f}\\n\"\n",
    "                    f\"DR: {row['DR']:.2f}\\n\\n\"\n",
    "                    f\"AUC: {row['AUC'].round(2)}\\n\"\n",
    "                    f\"F1: {row['F1 score'].round(2)}\\n\"\n",
    "                    f\"MCC: {row['MCC'].round(2)}\")\n",
    "\n",
    "    ax.text(1.05, 0.5, metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='center',\n",
    "            fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(root_dir+'/outputs/figs/TPAMI/locality_Oil_images.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsensors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
